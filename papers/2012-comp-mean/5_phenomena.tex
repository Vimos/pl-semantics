\section{Handling the phenomena}

[TODO: Explicitly mention excusion of meta-predicates: agent, patient, etc]

\subsection{Ambiguity in word meaning}

In order for our system to be able to make correct natural language inferences,
it must be able to handle paraphrasing.  For example, in order to license the
entailment pair in (\ref{ex:syn-hyp-pos}), the system must recognize that
``owns'' is a valid paraphrase for ``has'', and that a ``car'' is type of
``vehicle''.

\begin{example}\label{ex:syn-hyp-pos}
$p:$ Ed owns a car. \\
$h:$ Ed has a vehicle.
\end{example}

Perhaps the most natural fit for our system of projecting distributional
information into logical forms is trying to generate inference rules to address
lexical ambiguity.  For any natural language sentence $A$, a word $v$ in $A$ may
be replaced by a synonym of $v$, $w$, resulting in a new sentence $A'$.  The
degree to which $A'$ means the same thing as $A$ is determined by how well $w$
fits the context of $v$ in $A$.  Thus, in order to capture the probability that
$A$ entails $A'$, we want to generate an inference rule stating that $v$ implies
$w$ to the degree that that $w$ fits the context of $v$.

We can address this problem using the formalism introduced in
Section \ref{sec:interface}.

First, we generate a vector space $V$.  The vector space is generated from a
corpus in which all sentences have been lemmatized with the same lemmatizer used
by Boxer.  This ensures that the predicates output by Boxer will match the
points captured in the vector space.  The features used by $V$ are the N most
frequent dependency-relation/lemma pairs (ignoring stopwords).  Example features
might include $(has\text{-}subject,$ $dog)$ for which {\it fetch} might have a
high count, or $(object\text{-}of,$ $drive)$ for which {\it car} might be
frequent.  Each lemma in the corpus is represented by a vector in $V$.  To calculate these points, we
count the number of times the lemma appears in the same sentence each feature,
and then calculate the point-wise mutual information (PMI) between the lemma and
each feature.  The resulting PMI values are used as the vector for the lemma.
[TODO: Improve.]

Since we are concerned with measuring the similarity between points in our
vector space $V$, we require a {\it similarity function} $S$.  We define $S$
over vectors $\vec v$ and $\vec w$ to be to be simple cosine similarity \[
S(\vec v, \vec w) = cosine(\vec v, \vec w) = \frac{\vec v \cdot \vec w}{||\vec
v||~||\vec w||}\]

Logical forms in our system are generated by Boxer, so our logical language
\loglang is the set of formulas that may be returned from Boxer.  Likewise, the
set of predicate symbols $\predsym{\loglang}$ are the predicates generated by
Boxer. Boxer's predicates, as represented by the {\tt pred} relation in Boxer's
Prolog output\footnote{See
\url{http://svn.ask.it.usyd.edu.au/trac/candc/wiki/DRSs} for the detailed
grammar of Boxer DRS output.}, consist of a word lemma and a token index
indicating the original token that generated that predicate.  As such, our 
\emph{lexical mapping} $\ell$ simply returns the lemma portion of the predicate.

In order to assess the similarity between a word's context and a possible
replacement word, we must define a \textit{context mapping} that generates a
context from a predicate $P \in \predsym{\loglang}$ and a formula $G \in
\loglang$.  Since every predicate in a logical form returned by Boxer is indexed
with the sentence from which it was generated, we can define a simple context
mapping that defines a predicate's context solely in terms of the other
predicates generated by boxer for that sentence.
\begin{align*}
\kappa(P,G) = \{ (dummy\text{-}relation, \ell(Q)) ~|~ 
&~Q \text{ is a predicate found in } G, \\
&~Q\text{'s sentence index} = P\text{'s sentence index}, \text{ and } \\
&~Q \neq P \}
\end{align*}
As an alternative context mapping, we might want to take into
account the relation between predicates $P$ and $Q$.  To do this, we would
combine the output of Boxer with the corresponding output of the C\&C parser,
which contains dependency information.  Using the index information for each
predicate in the Boxer output, we can retrieve the relation connecting $P$ and
$Q$ and use it in a revised context mapping
\begin{align*}
\kappa'(P,G) = \{ (r_i, \ell(Q)) ~|~ 
&~Q \text{ is a predicate found in } G, \\
&~r_i = \text{the relation connecting } P \text{ and } Q, \text{ and } \\
&~Q \neq P \}
\end{align*}

Since the context mapping $\kappa$ returns a set as context, we require a
\textit{contextualization function} that converts this set into a vector in $V$.
Because our vector space is defined simply over lemmas, our contextualization
function just adds the vectors for each lemma in the context \[ \alpha(\vec v,
c) = \sum_{(r_i, \vec w_i) \in c} \vec w_i \]  Thus, the vector $\alpha(\vec v,
c)$ representing the context of word $v$ is simply the sum of vectors for the
words in that context.
[TODO: Again, we don't use \vec v.  Also: how can we modify $V$ to be able to
use $r_i$?]

Based on these definitions, we can compute the \textit{contextualized
substitution projection} $\Pi'_{S, \ell}(P)$, the set of weighted inference
rules mapping predicate $P$ to its potential replacements.


\subsubsection*{A lexical ambiguity example}

Assume we have sentence \eqref{ex:lexical-ambiguity}

\begin{example}\label{ex:lexical-ambiguity}
  A stadium craze is sweeping the country.
\end{example}

which is parsed by C\&C and translated into DRT by Boxer, as shown in Figure
\ref{drs:lexical-ambiguity}.

\begin{figure}
  \centering
  \subfloat[Dependency output from C\&C]{\label{drs:lexical-ambiguity-deps}
    \begin{tikzpicture}[level distance=50pt, sibling distance=30pt]
      \Tree 
        [.sweep
          \edge node[auto=right]{ncsubj}; [.craze  
            \edge node[auto=right]{det};   [.a ]
            \edge node[auto=left]{ncmod}; [.stadium ]
          ]
          \edge node[auto=right]{aux}; [.is ]
          \edge node[auto=left]{dobj}; [.country 
            \edge node[auto=left]{det}; [.the ]
          ]
        ]
    \end{tikzpicture}
	% (ncmod _ craze_2 stadium_1)
	% (det craze_2 A_0)
	% (det country_6 the_5)
	% (dobj sweeping_4 country_6)
	% (aux sweeping_4 is_3)
	% (ncsubj sweeping_4 craze_2 _)
  }
  ~~~~~~~~~
  \subfloat[DRT output from Boxer]{\label{drs:lexical-ambiguity-drs}
    ~~~~~~~~~~
	\drs{~x0 x1 x2 e3~}{
	  ~country_{1007}(x0)~ \\
	  ~stadium_{1002}(x1)~ \\
	  ~craze_{1003}(x2)~ \\
	  ~nn(x1, x2)~ \\
	  ~sweep_{1005}(e3)~ \\
	  ~event(e3)~ \\
	  ~agent(e3, x2)~ \\
	  ~patient(e3, x0)~
	}
	~~~~~~~~~~
  }
  \caption{Parse tree and DRT interpretation of \eqref{ex:lexical-ambiguity}}
  \label{drs:lexical-ambiguity}
\end{figure}

The DRS in Figure \ref{drs:lexical-ambiguity-drs}, a formula of logical language
\loglang, shall be denoted by $G$.  Formula $G$ contains a unary predicate
$sweep_{1005}$.  In order to generate weighted substitution rules for
$sweep_{1005}$, we calculate the {\it contextualized substitution projection} of
$sweep_{1005}$: the set of inference rules mapping $sweep_{1005}$ to each
(unary) predicate $Q \in \predsym{\loglang}^1$, with each rule weighted by the
similarity of the vector representing the context of $sweep_{1005}$ in $G$
to the vector representing the replacement $Q$\footnote{In reality, one might
limit the space of possible inference rules by using a resource such as
WordNet to ensure that the lemma of $Q$ is a synonym (or other closely related
word) of the target word {\it sweep}.}.
Since the unary predicate  occurs in exactly one formula, $G$, we calculate the 
contextualized substitution projection as 
\begin{align*}
\Pi'_{S, \ell}(sweep_{1005}) =  
\{ (F, \eta) \mid \exists Q \in \predsym{\loglang}^1~[ 
&~F = \forall x.[sweep_{1005}(x) \to Q(x)], \\
&~\eta = S\big(\alpha(\ell(sweep_{1005}), \kappa(sweep_{1005}, G)), \ell(Q)\big), \text{ and } \\
&~ \eta > 0 ~] \}
\end{align*}

Let us assume that our logical language \loglang also includes unary predicates
$cover_{2007}$ and $brush_{3004}$.  In other words, $\{ cover_{2007},~
brush_{3004} \} \in \predsym{\loglang}^1$.
So, in the calculation of $\Pi'_{S, \ell}(sweep_{1005})$, we will generate
weighted inference rules $(F,\eta)$ for both $cover_{2007}$ and $brush_{3004}$.

We look first at $cover_{2007}$.  The rule formula $F$ is instantiated simply as
$\forall x.[sweep_{1005}(x) \to cover_{2007}(x)]$.  The weight $\eta$ is the
similarity between the context of $sweep_{1005}$ in $G$, and $cover_{2007}$.
The context vector for $sweep_{1005}$ is calculated as \[
\alpha(\ell(sweep_{1005}), \kappa(sweep_{1005}, G)) \]  Since we defined the
lexical mapping $\ell(P)$ to simply return the vector from $V$ for the lemma
portion of the predicate $P$, $\ell(sweep_{1005}) = \vec{sweep}$ and
$\ell(cover_{2007}) = \vec{cover}$.  

The context of $P$ in $G$, $\kappa(P,G)$, uses the dependency parse information
found in Figure \ref{drs:lexical-ambiguity-deps} to construct a set of
predicates and their relations to $P$, so
\begin{align*}
\kappa(sweep_{1005}, G)
&= \{ (has\text{-}subject,~\ell(craze_{1003})),~ (has\text{-}object,~\ell(country_{1007})) \} \\ 
&= \{ (has\text{-}subject,~\vec{craze}),~ (has\text{-}object,~\vec{country}) \}
\end{align*}
We defined our contextualization function $\alpha(\vec v, c)$ to be the vector
sum of word vectors from the context $c$, so
\begin{align*}
\alpha(\ell(sweep_{1005}), \kappa(sweep_{1005}, G))
&= \alpha(\vec{sweep},~ \{ (has\text{-}subject,~\vec{craze}),~ (has\text{-}object,~\vec{country}) \}) \\
&= \vec{craze} + \vec{country}
\end{align*}

Finally, since we have the vector representing the context of $sweep_{1005}$ in
$G$ and the vector representing the replacement predicate $cover_{2007}$, we can
compute the weight, $\eta$ for our inference rule $\forall x.[sweep_{1005}(x)
\to cover_{2007}(x)]$ as
\begin{align*}
S\big(\alpha(\ell(sweep_{1005}), \kappa(sweep_{1005}, G)), \ell(Q)\big)
&= S\big(\vec{craze} + \vec{country},~ \vec{cover}\big) \\
&= cosine\big(\vec{craze} + \vec{country},~ \vec{cover}\big)
\end{align*}

Likewise, the rule for replacing $sweep_{1005}$ by $brush_{3004}$ would be 
$\forall x.[sweep_{1005}(x) \to brush_{3004}(x)]$, weighted by 
$cosine\big(\vec{craze} + \vec{country},~ \vec{brush}\big)$.

Since, $cosine\big(\vec{craze} + \vec{country},~ \vec{cover}\big) > 
cosine\big(\vec{craze} + \vec{country},~ \vec{brush}\big)$, {\it cover} is
considered to be a better replacement for {\it sweep} than {\it brush} in the
sentence ``A stadium craze is sweeping the country''.  Thus, the rule 
$\forall x.[sweep_{1005}(x) \to cover_{2007}(x)]$ will be given more
consideration during inference.


\subsection*{Hypernymy}

\begin{example}\label{ex:hyp-0}
$p:$ Ed owns a car. \\
$h:$ Ed has a automobile.
\end{example}

Even restricting rules to wordnet relationships, this works because car and
automobile are synonyms (in the same synset).
We construct rule 

$(w,~ car \to automobile)$ where w = $sim(ctx(car),~ automobile)$


\begin{example}\label{ex:hyp-1}
$p:$ Ed owns a car. \\
$h:$ Ed has a vehicle.
\end{example}

Even restricting rules to wordnet relionships, this works because vehicle is a
hypernym of (a sense of) car.
We can construct a rule 

$(w,~ car \to vehicle)$ where w = $sim(ctx(car),~ vehicle)$

\begin{example}\label{ex:hyp-2}
$p:$ Ed has a vehicle. \\
$h:$ Ed owns a car.
\end{example}

This is a less likely, but not altogether terrible entailment.
However, using wordnet strictly would fail since vehicle is a hypernym of (a
sense of) car.
So, instead of strictly limiting our rules to wordnet relationships, we could
have separate rules with separate weights:

$(w_1,~ vehicle \to car)$ where $w_1 = sim(ctx(vehicle), car)$ 

$(w_2,~ vehicle \to \lnot car)$ where $w_2$ = a measure of how far {\it car} and
{\it vehicle} are in the hierarchy.

So, we can say that, with certainty w1, that 'car' fits into 'vehicle''s context
based on distributional data.
Further, we can say with certainly w2 that 'vehicle' can be replaced with 'car'
based on ontology data.



\subsubsection*{Integration between logical and distributional phenomena}

Above, we stated that the entailment in \eqref{ex:hyp-1} was licensed because a
{\it car} is a type of {\it vehicle} and we can entail from a subset to a
superset.  In fact, the situation is complicated a bit because the direction of
entailment is actually dictated by the polarity of the context in which the
words appear.

Consider example \eqref{ex:hyp-3} below
\begin{example}\label{ex:hyp-3}
$p:$ Ed does not own a vehicle. \\
$h:$ Ed does not have a car.
\end{example}
This entailment is valid despite the fact that we are entailing from {\it
vehicle} to {\it car}, the opposite direction as in example \eqref{ex:hyp-1}. 
The difference is that in \eqref{ex:hyp-1}, the words appeared in a {\it
positive context} while in \eqref{ex:hyp-3} they appear in a {\it
negative context} since they are embedded under a single negation.

However, the approach that we have chosen to take handles this interaction
naturally.  The softened inference rules we generate for hypernym relationships
may lower the probability of entailment versus a similar hard rule (when the
weight is less than 1), but if an entailment rule does not fit the polarity of
the context, then it will not raise the probability of entailment.

In addition to negation, other linguistic constructs such as quantifiers and
implicative verbs may affect the polarity of a context
\citep{maccartney:iwcs2009}.  Our system handles all equally well.




\subsection*{Implicatives and factives}

\citet{nairn:icos2006} presented an approach to the treatment of inferences
involving implicatives and factives.  Their approach identifies an ``implication
signature'' for every implicative or factive verb that determines the truth
conditions for the verb's nested proposition, whether in a positive or negative
environment.  Implication signatures take the form ``$x/y$'' where $x$
represents the implicativity in the the positive environment and $y$ represents
the implicativity in the negative environment.  Both $x$ and $y$ have three
possible values: ``+'' for positive entailment, meaning the nested proposition
is entailed, ``-'' for negative entailment, meaning the negation of the proposition
is entailed, and ``o'' for ``null'' entailment, meaning that neither the
proposition nor its negation is entailed. Figure \ref{fig:imp-sig} gives
concrete examples.% for two signatures.

% For example, the verb ``managed to'' has positive entailment in the {\it true}
% case and negative entailment under negation.  So, {\it he managed to escape
% $\vDash$ he escaped} while {\it he did not manage to escape $\vDash$ he did not
% escape}.  On the other hand, the verb ``refused to'' has negative entailment
% in the positive case and ``null'' entailment under negation.  So, {\it he
% refused to fight $\vDash$ he did not fight} but {\it he did not refuse to fight}
% entails neither {\it he fought} nor {\it he did not fight}.

\begin{figure}
\begin{center}
  \begin{tabular}{l c l}
    \hline
   	 & ~~~~~~signature~~~~~~ &  \multicolumn{1}{c}{example} \\
   	\hline
%    	admitted that    & +/+ & he admitted that he knew $\vDash$ he knew \\
%    	                 &     & he did not admit that he knew $\vDash$ he knew \\
%    	\hline
   	forgot that      & +/+ & he forgot that Dave left $\vDash$ Dave left \\
   	                 &     & he did not forget that Dave left $\vDash$ Dave left \\
   	\hline
%    	pretended that   & -/- & he pretended he was sick $\vDash$ he was not sick \\
%    	                 &     & he did not pretend he was sick $\vDash$ he was not sick\\
%    	\hline
%    	wanted to        & o/o & he wanted to fly $?$ he flew \\  
%    	                 &     & he did not want to fly $?$ he flew \\
%    	\hline
   	managed to       & +/- & he managed to escape $\vDash$ he escaped \\
   	                 &     & he did not manage to escape $\vDash$ he did not escape \\
   	\hline
%    	was forced to    & +/o & he was forced to sell $\vDash$ he sold \\
%    	                 &     & he was not forced to sell $?$ he sold \\
%    	\hline
%    	was permitted to & o/- & he was permitted to leave $?$ he left \\
%    	                 &     & he was not permitted to leave $\vDash$ he did not leave \\
%    	\hline
   	forgot to        & -/+ & he forgot to pay $\vDash$ he did not pay \\
   	                 &     & he did not forget to pay $\vDash$ he paid \\
   	\hline
   	refused to       & -/o & he refused to fight $\vDash$ he did not fight \\
   	                 &     & he did not refuse to fight $\nvDash$ \{he fought, he did not fight\} \\
   	\hline
%    	hesitated to     & o/+ & he hesitated to ask $?$ he asked\\
%    	                 &     & he did not hesitate to ask $\vDash$ he asked \\
%    	\hline
  \end{tabular}
\end{center}
\caption{Implication Signatures}
\label{fig:imp-sig}
\end{figure}


\subsubsection*{Inferences with nested propositions}

The standard conversion from DRT to first-order logic (FOL) (the one used by
Boxer), falls short on nested propositions.  Consider the entailment pair ``John
did not manage to leave'' and ``John left''.  The DRT interpretation and its
corresponding FOL conversion are are shown in Figure \ref{drs:impl-1}.

\begin{figure}
  \centering
  \subfloat[DRT interpretation]{\label{drs:impl-1-drt}
    ~~~~~~~~
	\drs{~x0~}{
	  ~john_{1001}(x0)~ \\
	  \negdrs{~e1 p2~}{
	    ~manage_{1004}(e1)~ \\
	    ~agent(e1, x0)~ \\
	    ~theme(e1, p2)~ \\
	    ~p2:~\drs{~e3~}{
	      ~leave_{1006}(e3)~ \\
	      ~agent(e3, x0)~
	    }
	  }
	}
	~~~~~~~~
  }
  ~~~~~~~~~
  \subfloat[FOL translation]{\label{drs:impl-1-fol}
    \dhgboxed{$
      ~\exists~ x0.[
      ~  john_{1001}(x0) ~\&~ \\
      ~  \hspace{18px} \lnot \exists~ e1 p2.[
      ~                  manage_{1004}(e1) ~\&~ \\
      ~    \hspace{55px} agent(e1, x0) ~\&~ \\
      ~    \hspace{55px} theme(e1, p2) ~\&~ \\
      ~    \hspace{55px} \exists~ e3.[
      ~                    leave_{1006}(e3) ~\&~ \\
      ~      \hspace{77px} agent(e3, x0) ]]]
    $}
%     ~~~~~~~~
% 	\drs{~x0 e1~}{
% 	  ~john_{2001}(x0)~ \\
% 	  ~leave_{2002}(e1)~ \\
% 	  ~agent(e1, x0)~
% 	}
% 	~~~~~~~~
  }
  \caption{Boxer's DRT interpretation of ``John did not manage to leave.''.}
  \label{drs:impl-1}
\end{figure}

While it should be clear that ``John did not manage to leave'' does {\it not}
entail ``John left'' (and, in fact, entails the opposite), the FOL formula shown
in Figure \ref{drs:impl-1-fol} {\it does} entail the FOL representation of
``John left'' \[ \exists~ x0~e1.[john_{1001}(x0) ~\&~ leave_{1006}(e1) ~\&~
agent(e1, x0)] \]  

The incorrect inference occurs here because the standard DRT-to-FOL translation
loses some information.  DRT expressions are allowed to have {\it labeled
subexpressions}, such as $p2$ in Figure \ref{drs:impl-1-drt} that is used to
reference the {\theme} of the {\it manage} event: the {\it leave} event.  The
FOL expression, on the other hand, shows that $p2$ is the theme of event $e1$,
but has no way of stating what $p2$ refers to.

In order to capture the information that the DRT labels provide, we modify the
DRT expression to contain explicit {\it subexpression triggers}.  That is, for a
sub-DRS $A$ labeled by $p$, we replace $A$ with two new expressions in the same
scope: $POS(p) \to A$ and $NEG(p) \to \lnot A$.  The result of such a
replacement on the DRS in \ref{drs:impl-1-drt} can be see in Figure
\ref{drs:impl-2-drt}.   

\begin{figure}
  \centering
  \subfloat[DRT interpretation with subexpression triggers]{\label{drs:impl-2-drt}
	\drs{~x0~}{
	  ~john_{1001}(x0)~ \\
	  ~\drs{~p2~}{
	    ~\negdrs{~e1~}{
	      ~manage_{1004}(e1)~ \\
	      ~theme(e1, p2)~ \\
	      ~agent(e1, x0)~} \\
	    \unboxedifdrs{POS(p2)}{   \drs{~e3~}{~leave_{1006}(e3)~ \\ ~agent(e3, x0)~}} \\
	    \unboxedifdrs{NEG(p2)}{\negdrs{~e3~}{~leave_{1006}(e3)~ \\ ~agent(e3, x0)~}}
	  }
	}
  }
  ~~~~~~~~~
  \subfloat[Subexpression-triggering inference rules for implicative ``manage
            to'' with signature +/-]{\label{drs:impl-2-rules} 
  \shortstack{
      \unboxedifdrs{\drs{~p~}{~   \drs{~e~}{~manage_{1004}(e)~ \\ ~theme(e, p)~}~}}{POS(p)} \\
      \\\\\\\\\\\\
      \unboxedifdrs{\drs{~p~}{~\negdrs{~e~}{~manage_{1004}(e)~ \\ ~theme(e, p)~}~}}{NEG(p)}
    }
  }
  \caption{First (insufficient) attempt at correcting for the loss of labeled
  sub-expression information.}
  \label{drs:impl-2}
\end{figure}

Now that our labeled subexpression has triggers, we can introduce inference
rules to activate those triggers.  The purpose of these inference rules is to
capture the behavior dictated by the implication signature of the implicative
verb for which the relevant subexpression is the theme.  For example, according
to the implication signature, the implicative {\it manage to} is positively
entailing in positive contexts and negatively entailing in negative contexts.
This means that if John {\it managed to} do what is described by $p$, then the
event described by $p$ occurred, or in other words, the subexpression of $p$ is
{\it true}. Likewise, if John {\it did not manage to} do what is described by
$p$, then the event described by $p$ {\it did not} occur, meaning that the
subexpression of $p$ is {\it false}.  

The triggering inference rules for {\it managed to} are shown in Figure
\ref{drs:impl-2-rules}.  The first rule, for positive contexts, says that for
all propositions $p$, if $p$ is ``managed'', then $p$'s subexpression is {\it
true}, so trigger the ``positive entailment'' subexpression which, in our
example, says that the {\it leaving} event occurred.  The second rule, for
negative contexts, says that for all propositions $p$, if there is {\it no}
``managing'' of $p$, then $p$'s subexpression is {\it false}, so trigger the
``negative entailment'' subexpression to say that there is {\it no} event of
{\it leaving}.

While this approach works for positive contexts, there is a subtle problem for
negative contexts.  The negative context rule in Figure \ref{drs:impl-2-rules}
can be translated to FOL as \[ \forall~ p.[~ \lnot \exists~ e.[~ manage(e) \land
theme(e,p)) ~] \to NEG(p) ~] \] This expression is stating that for all
propositions $p$, $p$ is {\it false} if there is no ``managing'' of $p$.  Now,
we want this inference rule to be used in cases where it is stated that
``managing'' did not occur, such as in the expression of Figure
\ref{drs:impl-2-drt}, where we see that is is the case that \[ ~\negdrs{~x0 e1
p2~}{ ~manage_{1004}(e1)~ \\ ~agent(e1, x0)~ \\ ~theme(e1, p2)~} \] which is
equivalent to the FOL expression \[ \lnot manage_{1004}(e1) \land \lnot
agent(e1, x0) \land \lnot theme(e1, p2) \] stating that $e1$ is a ``managing''
of $p2$ by $x0$.  However, the antecedent of our negative context rule states
that there is {\it no} ``managing'' of the proposition, so the rule would only
be used if it could be proven that there is no ``managing'' at all.
Unfortunately, stating that $p2$ is not ``managed'' {\it by x0} does {\it not}
entail that $p2$ is not ``managed'' at all since $p2$ could be managed by
someone other than $x0$.

To overcome this problem, we modify our representation of a negated event. 
Instead of representing an event, such as the ``managing'' event, that that
{\it did not} occur as $\lnot \exists~ e.[~ manage(e) ~]$, we represent it
explicitly as an event of {\it non-occurrence}: $\exists~ e.[~
\textbf{not\_}manage(e) ~]$.  Applying this change to the DRS and inference
rules in Figure \ref{drs:impl-2}, we arrive at our final form in Figure
\ref{drs:impl-3}.

\begin{figure}
  \centering
  \subfloat[DRT interpretation with subexpression triggers]{\label{drs:impl-3-drt}
	\drs{~x0~}{
	  ~john_{1001}(x0)~ \\
	  ~\drs{~e1 p2~}{
	    ~\textbf{not\_}manage_{1004}(e1)~ \\
	    ~theme(e1, p2)~ \\
	    \negdrs{ }{~agent(e1, x0)~} \\
	    \unboxedifdrs{POS(p2)}{\drs{~e3~}{~              leave_{1006}(e3)~ \\ ~agent(e3, x0)~}} \\
	    \unboxedifdrs{NEG(p2)}{\drs{~e3~}{~\textbf{not\_}leave_{1006}(e3)~ \\ \negdrs{ }{~agent(e3, x0)~}}}
	  }
	}
  }
  ~~~~~~~~~
  \subfloat[Subexpression-triggering inference rules for implicative ``manage
            to'' with signature +/-]{\label{drs:impl-3-rules} 
  \shortstack{
      \unboxedifdrs{\drs{~p~}{~\drs{~e~}{~              manage_{1004}(e)~ \\ ~theme(e, p)~}~}}{POS(p)} \\
      \\\\\\\\\\\\
      \unboxedifdrs{\drs{~p~}{~\drs{~e~}{~\textbf{not\_}manage_{1004}(e)~ \\ ~theme(e, p)~}~}}{NEG(p)}
    }
  }
  \caption{Explicit capturing of sub-expression information.}
  \label{drs:impl-3}
\end{figure}

Using this strategy, we can see that the negative context rule is active when
there exists a ``not-managing'' event, and the representation of ``John did
not manage to leave'' explicitly states that there is such an event, meaning
that the rule will be used in the inference.  With all of these pieces in place,
the inference works as expected.

Thus, we transform the output of Boxer in two ways.  First, we identify any
labeled propositions and replace them with pairs of proposition triggers.  Then,
we modify any negated DRSs by extracting the verb and theme atoms, changing the
verb predicate to a ``not\_'' predicate, and finally ensuring that all other
expressions under the negated DRS (aside from the labeled proposition itself),
remain under a negated DRS.

Once the sentence representations have been modified, we generate inference
rules for each implicative verb.  If the verb is positively entailing in
positive contexts, we generate a rule of the form 
\[ \forall~ p.[~ \exists~ e.[~ \langle verb \rangle(e) \land theme(e,p)) ~] \to POS(p) ~] \]
but if it is negatively entailing in positive contexts, we instead generate a rule of the form
\[ \forall~ p.[~ \exists~ e.[~ \langle verb \rangle(e) \land theme(e,p)) ~] \to NEG(p) ~] \]
If the verb is positively entailing in {\it negative} contexts, we generate a rule of the form
\[ \forall~ p.[~ \exists~ e.[~ \textbf{not\_}\langle verb \rangle(e) \land theme(e,p)) ~] \to POS(p) ~] \]
but if it is negatively entailing in negative contexts, we instead generate a rule of the form
\[ \forall~ p.[~ \exists~ e.[~ \textbf{not\_}\langle verb \rangle(e) \land theme(e,p)) ~] \to NEG(p) ~] \]
If the verb is non-entailing in either positive or negative contexts, then we do
not generate a rule for that context polarity. 

This approach works for arbitrarily long chains of nested implicatives.  It also
interacts properly with 



\subsubsection*{Use of subcategorization frame}

The the verb {\it forget} has different implicative properties depending on its
subcategorization frame.  When used as {\it forget that}, as in ``He forgot that
Dave left'', it is positively entailing in both positive and negative contexts. 
When used as {\it forget to}, as in ``He forgot to lock the door'', it is
negatively entailing in positive contexts and positively entailing in negative
contexts.

In order to generate the correct inference rules, the right implication
signature must be selected.  To do this, we make use of the dependency parse
generated by the C\&C parser that is input to Boxer.  The parse tells us which
version of the verb is being used.  In our example ``He forgot that
Dave left'', {\it forgot} has a ``ccomp'' relationship to the {\it left}, while
in ``He forgot to lock the door'', {\it forgot} has a ``xcomp+to'' relationship
to {\it lock}.



\subsubsection*{Weighting implicative inference rules}

While we do not have a scheme for generate such weights at this time, one of the
advantages of our approach is that it allows for the independent weighting of
each implicative inference rule in isolation.  

