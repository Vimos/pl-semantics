-"repeat" in AutoConst is wrong. Fix it <<<<<<<<<<<
-Introduction in SetGoal should reduce number of constants somehow <<<<<< 
-AutoConst is missing a case <<<<<<<<
-There are more "there" to be removed <<<<<<<
-pair 790 throws StackOverflow exception
-pairs 67,260,368,3197 throw StackOverflow exception
-A false sub-formula in Q should not be removed. Try pair 1356 with and without NoExist. Done. Alchemy breaks in this case, and NoExist supposed to be avoiding these cases.
-Check the case in AutoConst where agent propagates evidence to predicates then these predicates mistakenly propagate more evidnece back to agent <<<
-Get latest vesrion of Boxer for handling of "there"
-Again, it seems that the handling of negation is wrong again. Try pair 2324
-There is a problem similar to the unicorn case in (prb-23-h|NotT)
-Output of pairs: 20-32 showing errors: [1.0000,0.0000  1.0000,0.0000  1.0000,0.0000  1.0000,-1.0000  -3.0000,0.0000  -3.0000,-1.0000  1.0000,0.0000  1.0000,-3.0000  1.0000,-3.0000  1.0000,0.0000  1.0000,0.0000  1.0000,0.0000  1.0000,0.0000]
-I think equalities are messed up in NoExistProbabilisticTheoremProver
-PositiveEqEliminatingProbabilisticTheoremProver has to be removed. THen, equality handling goes into SetGoal 
-P(H|-T) takes forever for some examples like : 34,190,502,682,717
--run the following and explain why hundereds of skolem_1 are generated
alchemy/bin/infer -i /tmp/temp-3270558921426446116.mln -e /tmp/temp-3666499365217559437.db -r /tmp/temp-8210559381267654219.res -ss -maxSeconds 5 -ssq /tmp/temp-2905646586885501927.q -q entailment_h,compnay_n_dh,guy_n_dh,own_v_dh,r_patient_dh,r_agent_dh,skolem_1  -focusGround 

-Add the semantic role uniqueness constraint. PSL and MLN. 
-Semantic role uniqueness constrain added to PSL but it is not working because weight of relation predicates is zero. Fix this
-add a negation predicate in PSL-STS. 
-Try multiple weights between relation predicates and entities predicates 
Make PSL works for RTE. Negation in Premise is fine. Negation in hypothesis is very wrong
-----
Alchemy:
-probably I will have to generate constants in the function "propagate"
-predicates of more than two args are possible
-intersection of possible constats is wrong. It does not handle ANY right
-take source of consts into acount
-why "all birds do not fly    no bird flies" should equal 1
-generate negative evidence also for the negated existentially quantified variables. 
-more negative evd can be generated or a^r1^b=>c^r2^d. Arrows have conjunction. 
-make the application of the negative evidence prior to converting to CNF. May be this can be done with some manipulation of the typing system.
-make sure it is strict subset
-There is a case where picking the smaller-sized type is not enough. 
-Do not forget the typing problem when handling existential quantifier
-in progress two exp, condor/sick-rte-ir0-noIntro and condor/sick-rte-ir0-noIntroVerylong. Both Introduction is disabled(this messes negation and universal)
-count univ and exist to decide negate or not
-find the rule of everything, where NotExist is treated as Univ
-Do not forget the unicorn. It has examples in the SICK ds
-In sample search, it is better to go back to log10. No
-What to do with relation predicates with one univ, one exist var. Ignore it.
-Contradicting MLNs return Z=1 but it should return Z=0
-How to do negation in text and hypothesis ? 
-When to negate H and when not ? (for computational efficieny). Looks like always negate
-Parsing bug in deallocation alchemy/src/parser/listobj.h. For now, deallocation disabled
-FIXED: Why IR changes affects p(-H) and p(H) differently ? (They do not).
-FIXED: Why p(H) not equal 1-p(-H) ?  Beucase of bug in parsing. Bug fixed
-FIXED: try examples 24,25,27,28 for more bugs in alchemy. Done
-FIXED: Infinite loop in HardAssumptionAsEvidenceProbabilisticTheoremProver in example 13. 
-FIXED: wierd handling of a formula like a(x)^b(y).
-FIXED: wrong handling of weights: infinity + w = 10 + w
-----------
SampleSearch:
-GM::reduceDomains can be better by removing functions that are always true
-what to do with LogFunction.h
-what to do with CPT.h
-what to do with SF.h
-------------------
-still, there are types problems in inference rules. I will disable recovering types for the current experiments
-paraphrase to logic
-prenex normal form 
-multiparses and svm
-get latest candc and boxer
-try to tune candc parameters to reduce no-parse 

-Can we use !H instead of H<->ent  to avoid the problem of H- ?
-H- now is bad bad bad.
-OR in PositiveEqEliminating could be wrong
-Negation in PositiveEqEliminating and HardAssumptionAsEvidence is absolutely wrong.

1-Naming of HardAssumptionAsEvidence and PositiveEqEliminating is not decriptive
5-fixDCA or noFixDCA is not implemented in PositiveEqEliminating (well, it automatically works if "-keepUniv false")

3-Existance is done for the outer most group of universals, not for embeded univs under exists
SUggestion: 
-STS is running RTE twice then average. Do not do both of them in one big MLN

how to parse multi-sentences T or H

//==========================================
Merging Cuong's fork with main(ToDo)
------------------------------
* Code of running condor is replaced with my scripts for condor. What is still missing is organizging the output and running the scripts on it. 
-Different sets of scripts are required for different data sets, STS, RTE, and Baroni

* Run the system on Torrento's dataset with their phrases.

* In AlchemyTheoremProver.scala, there is a function to generate rules based on wordnet, it is commented for now but it should not
//==========================================

-Function: InferenceRuleInjectingProbabilisticTheoremProver.convertParaphraseToFOL is completely wrong. 
espcially, How to map variables from LHS to RHS ? do we use a new Existential Quantifier ? 
Now, the mapping is so messed up. It is as it was implemented by coung
It is even worse. Now, it assumes that the phrases are a list of conjuncted predicates. This is wrong, we have rules contain negations. 

-How to generate rules for phrases. We need a principled way to extract phrases and map them to logical expressions.
Assuming we follow the technique we have now, there still a problem with it. e.g:
 A little boy is playing.	A fat girl is eating.
Phrases are: 
little boy	(correct)
fat girl	(correct)
little boy play	(not sure)
little play	(not sure)
boy play	(not sure)
fat girl eat	(not sure)
girl eat	(not sure)
fat eat		(not sure)
For now, all of them are possible phrases.

-Locking in Lucene will prevent parallalization in condor. 

-Tokenization:
Tokenization details and different modes of tokenization are in utcompling/mlnsemantics/datagen.Tokenize.scala

-Removing special characters: It is two steps, 
(a) removing quotes if the text is quoted before generating inference rules.  
(b) replace special characters with _ before convert to FOL in PredicateCleaningBoxerExpressionInterpreterDecorator
Is this the right place ? Should not it be right before calling MLN/PSL ? would it be better NOT to remove special characters. Instead, replace them with some other characters ?  I will keep it like this for now until I find an example where this needs to be changed. 
In all cases, candc gets somehow confused when parsing special characters. 
//==========================================Future enhancements
-When supporting embeded proposition, UnnecessarySubboxRemovingBoxerExpressionInterpreter has to change  (unremove theme and propositions)
-When parsing, WH questions are removed. This can be fixed here: BoxerExpressionParser
-Weighted universal rule to simulate generalized quantifiers.
//==========================================
830: takes 18 minutes: it is slightly changed to avoid this loong wait

597: type
610: type
679: type
803: type
1399: type


825: parsing (%) should be added to the forbidden char
904: parsing (#) should be added to the forbidden char
905: NotEqual: two variables unmatching types
1067: parsing (%) should be added to the forbidden char
1171: parsing (%) should be added to the forbidden char
1341: parsing (@) should be added to the forbidden char

1446: parsing (@) should be added to the forbidden char


remove predicates named topic_

remove _loc_, _nam_ ...


133: wrong parse
564: need a long paraphrasing rule
918: add a rule between two predicates if their characters are matching. E.g sew and sewing. 
940: we do not fix spelling mistakes. Maybe the hack above could help
152: kengaroo. Why do not we remove _POS_ ?? THink carefully about it. 
1321: people vs group of people
1024: wrong parse. pizza vs slice of pizza
245: wrong parse
852: wrong parse
951: wrong spelling of kangaroo. Slightly low weights. Solution on 918 may help a bit
DO WE ALLOW rules between non-matching POS predicates ???
963: terrible wrong parse for a very easy sentence. easy paraphrasing rule: chop up vs dice
1305: terrible wrong parse. No workaround can fix it.
95: wrong parse
1488: boxer's nasty way of doing AND
1040: wrong parse
9: crappy boxing. It needs clever code.
1131: paraprasing: apply butter = puttering, peice of bread vs bread
1449: missed correference resolution. how do handle "neuter" ?
223: wrong parse. 
7: verctor space weight is very very low. 
11: very low combination weights in case of very few lines

1072: try to replace all relations with REL instead of the name
r_of_dt(x, y) <=>  r_on_dt(y, x)
r_and_dh(x, y) => r_and_dh(y,x)

Try BP

Try removing all rel except agent, patient

terrible overestimated in PAR: 674, 531, 541, 712
=========================================================
PSL
2-Is it better to limit number of nulls ? 

3-replace "all" with "default". 

4-grounding of avg, entailment_h & entailment_t >> entailment  does not work correctly if one of the two predicates in the LHS is zero. It works as AND not AVG

5-Timeout: 498, 517, 664
Ill-posed optimization: 960, 1431
Zero because of error 4 above: 592, 924, 1418

============================================================
Logic: 
-Handling negation is wrong.  For now, it is replaced with dummy predicate
-Handling some of the equality contstraints is also wrong
