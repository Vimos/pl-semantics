New testing and development phase starts end of July 2014
-Suggestion: hard-coded rules. It would be great if I can get 100% accuracy with the hard-coded rules
-Suggestion: MOST and FEW problem (what about NOT, EXACTLY, MANY): Check entailment as if it is EXIST, then apply modality rules in a separate step. 
-Remember to test also on the test-set of SICK, not only the training set
RUntime errors: 363,523,2432,2434,2561,3368,3374,3433,3590,3953,3954,3955,4340,4341,4342,4343,4344,4345,4570,4571
SCRIPT: grep -E "actual:.*-|Pair" condor/afterconf-sick-test-rte-fixpermute-noir-lhsonlyintro/*.out  | grep actual -B 1 | grep '\-\-' -v | tr '\n' ' ' | tr ']' '\n' | awk '{print $3 "\t" $6}' | tr ',' ' ' | sort -n
363	0.0:-3.0 
523	-2.0:-2.0 
2432	-2.0:-2.0 
2434	-2.0:-2.0 
2561	0.06102399999999997:-5.0 
3368	0.0:-3.0 
3374	0.0:-3.0 
3433	0.0:-1.0 
3590	0.0:-3.0 
3953	0.0:-1.0 
3954	0.0:-1.0 
3955	0.0:-1.0 
4340	-1.0:-1.0 
4341	-1.0:-1.0 
4342	-1.0:-1.0 
4343	-1.0:-1.0 
4344	0.0:-1.0 
4345	0.0:-1.0 
4570	0.0:-3.0 
4571	-3.0:1.0

Inference errors: 86,448,812,964,976,1186,1207,1212,1237,1303,1362,1465,1528,1575,1799,1815,2179,2277,2434,2521,3084,3209,3228,3635,3676,3693,3809,4408,4502,4602
    86        1:0        3:1   +   1 
   448        1:0        3:1   +   1 
   812        1:0        3:1   +   1 
   964        1:0        3:1   +   1 
   976      2:0.5        3:1   +   1 
  1186      2:0.5        3:1   +   1 
  1207        1:0        3:1   +   1 
  1212      2:0.5        3:1   +   1 
  1237      2:0.5        1:0   +   1 
  1303      2:0.5        1:0   +   1 
  1362      2:0.5        1:0   +   1 
  1465      2:0.5        3:1   +   1 
  1528        1:0        3:1   +   1 
  1575      2:0.5        3:1   +   1 
  1799      2:0.5        1:0   +   1 
  1815      2:0.5        1:0   +   1 
  2179      2:0.5        1:0   +   1 
  2277      2:0.5        1:0   +   1 
  2434      2:0.5        3:1   +   1 
  2521        1:0        3:1   +   1 
  3084        1:0        3:1   +   1 
  3209        1:0        3:1   +   1 
  3228      2:0.5        3:1   +   1 
  3635        1:0        3:1   +   1 
  3676        1:0        3:1   +   1 
  3693      2:0.5        3:1   +   1 
  3809        3:1        1:0   +   1 
  4408        1:0        3:1   +   1 
  4502        1:0        3:1   +   1 
  4602        1:0        3:1   +   1 
-Check the error code -7 in alchemy/src/logic/clause.cpp becuase it looks like it is not needed. For example, pair 9 in prb after disabling groundExist and negating hypothesis
-Check the effect of combination-permutation vs combination only. combination only is wrong. It is applied in HardAssumptionAsEvidenceProbabilisticTheoremProver and NoExistProbabilisticTheoremProver. Disable it, run experiment, then enable it and test again. Done. Works better with same accuracy
-run experiment with -lhsOnlyIntro true. Done. Works extreamly faster with the same accuracy.
-Implement the AutoTyping on the HardAssumptionAsEvidenceProbabilisticTheoremProver then run pair 25 in prb. 
-Cases of domain with no constants but the default need a second look because they give none 0/1 answers. For exmple, sick-rte 4,6 and prb 29,31. Also, add to these examples the non-0/1 results of the run afterconference-sick-rte-noIR-fixPermute-lhsOnlyIntro
-examples with runtime errors: 167,288,366,412,788,790,791,792,949,2707,2709,2710,3618,3767,4476,4723,4725 (all of them are classified correctly)
Some answered, remanining: 288,366,412,788,791,792,3618,4476,4723,4725
167	0.0:-3.0		Need longer timeout
288	-1.0:0.0 	
366	-1.0:0.0 
412	-3.0:0.0 
788	0.0:-3.0 
790	1.0:-1.0		Need longer timeout
791	1.0:-3.0 
792	0.0:-3.0 
949	-2.0:-2.0	Parsing error
2707	-2.0:-2.0 	Parsing error
2709	-2.0:-2.0 	Parsing error
2710	-2.0:-2.0 	Parsing error
3618	-1.0:0.0 
3767	-1.0:0.0 	Need longer timeout 
4476	-1.0:-1.0 
4723	-1.0:-1.0 
4725	-1.0:-1.0 
-examples that are predected to be Neutral but supposed to be otherwise are probably because lake of IR. Few examples are not in this class, and they should be carefully studied. They are: 458,642,974,1003,1145,1196,1227,1240,1371,1531,1653,1991,2049,2195,2521,3346,3738,3897,3899,4505
Details:
   458      2:0.5        1:0   +   1  Unknown. "There is no cat eating corn on the cob		A cat is eating some corn. Inference makes sense", annotation makes sense, do not know where the problem is.
   642      2:0.5        1:0   +   1  Wrong annotation, our system gets it right
   974        1:0        3:1   +   1  Misparse. What is peacefull, the girl or the lying ?
  1003      2:0.5        3:1   +   1  None 0/1 Pr. No constants generated except the default, and one default is not enough to get the right result.
  1145        1:0        3:1   +   1  Misparse or missing rule: r_over_dh(x, y) <=> (over_a_dh(x) ^ r_patient_dh(x, y)).
  1196        1:0        3:1   +   1  Weird interaction between "A" and "The" + missing rule. With the rule, problem solved
  1227      2:0.5        3:1   +   1  1)Missing rule r_onto_dh(x,y)<=>r_into_dh(x,y), 2)wrong handling of inconsistent mln, 3)Weird interaction between "A" and "The"
  1240        1:0        3:1   +   1  1)Missing rule man_n_dh(x)<=>person_n_dh(x), 2)Scope of negation, the same like the weird "A", "The"
  1371        1:0        3:1   +   1  1)Misparse or missing rule: man(x) ^ intensely(x) ^ agent(y,x) ^ play(y) = man(x) ^ agent(y,x) ^ play(y)^ intensely(y) 2)Negation scope like the weird interaction mentioned above  
  1531        1:0        3:1   +   1  1)Missing rule: wakeboard_v_dt(x)<=>waterskie_v_dh(x) 2)None 0/1 pr that can be solved by lhsIntro for negation
  1653        1:0        3:1   +   1  1)Missing rule: dog_n_dh(x) => exist y r_of_dh(x,y) ^ dog_n_dh(x) ^ bull_n_dh(y), 2)Negation scope
  1991        1:0        3:1   +   1  1)Misparse 2)None 0/1 pr that can be solved by lhsIntro for negation   
  2049      2:0.5        1:0   +   1  Unknown like 458 
  2195      2:0.5        1:0   +   1  Unknown like 458. Or may be it is the negation scope
  2521      2:0.5        1:0   +   1  Generalized quantifier: Exaclty 2 vs Some 
  3346      2:0.5        3:1   +   1  Unknown 
  3738        1:0        3:1   +   1  Scope of negation 
  3897        1:0        3:1   +   1  Scope of negation
  3899        1:0        3:1   +   1  Scope of negation 
  4505      2:0.5        1:0   +   1  Wrong annotation, our system gets it right


---------------------------
===========================
Things to try: fixed AutoType, repeat, noRelIntro, IR W * 3
-"repeat" in AutoConst is wrong. Fix it <<<<<<<<<<<
-Introduction in SetGoal should reduce number of constants somehow <<<<<< 
-AutoConst is missing a case <<<<<<<<
-There are more "there" to be removed <<<<<<<
-pair 790 throws StackOverflow exception <<<<<<<<<<,
-pairs 67,260,368,3197 throw StackOverflow exception
-A false sub-formula in Q should not be removed. Try pair 1356 with and without NoExist. Done. Alchemy breaks in this case, and NoExist supposed to be avoiding these cases.
-Check the case in AutoConst where agent propagates evidence to predicates then these predicates mistakenly propagate more evidnece back to agent <<<
-Get latest vesrion of Boxer for handling of "there"
-Again, it seems that the handling of negation is wrong again. Try pair 2324
-There is a problem similar to the unicorn case in (prb-23-h|NotT)
-Output of pairs: 20-32 showing errors: [1.0000,0.0000  1.0000,0.0000  1.0000,0.0000  1.0000,-1.0000  -3.0000,0.0000  -3.0000,-1.0000  1.0000,0.0000  1.0000,-3.0000  1.0000,-3.0000  1.0000,0.0000  1.0000,0.0000  1.0000,0.0000  1.0000,0.0000]
-I think equalities are messed up in NoExistProbabilisticTheoremProver
-PositiveEqEliminatingProbabilisticTheoremProver has to be removed. THen, equality handling goes into SetGoal 
-P(H|-T) takes forever for some examples like : 34,190,502,682,717
--run the following and explain why hundereds of skolem_1 are generated
alchemy/bin/infer -i /tmp/temp-3270558921426446116.mln -e /tmp/temp-3666499365217559437.db -r /tmp/temp-8210559381267654219.res -ss -maxSeconds 5 -ssq /tmp/temp-2905646586885501927.q -q entailment_h,compnay_n_dh,guy_n_dh,own_v_dh,r_patient_dh,r_agent_dh,skolem_1  -focusGround 

-Add the semantic role uniqueness constraint. PSL and MLN. 
-Semantic role uniqueness constraint is not enough. We actually need a NotEqual in many places in the hypothesis, in both RTE and STS. 
-Semantic role uniqueness constrain added to PSL but it is not working because weight of relation predicates is zero. Fix this
-add a negation predicate in PSL-STS. 
-Try multiple weights between relation predicates and entities predicates 
Make PSL works for RTE. Negation in Premise is fine. Negation in hypothesis is very wrong
-----
Alchemy:
-probably I will have to generate constants in the function "propagate"
-predicates of more than two args are possible
-intersection of possible constats is wrong. It does not handle ANY right
-take source of consts into acount
-why "all birds do not fly    no bird flies" should equal 1
-generate negative evidence also for the negated existentially quantified variables. 
-more negative evd can be generated or a^r1^b=>c^r2^d. Arrows have conjunction. 
-make the application of the negative evidence prior to converting to CNF. May be this can be done with some manipulation of the typing system.
-make sure it is strict subset
-There is a case where picking the smaller-sized type is not enough. 
-Do not forget the typing problem when handling existential quantifier
-in progress two exp, condor/sick-rte-ir0-noIntro and condor/sick-rte-ir0-noIntroVerylong. Both Introduction is disabled(this messes negation and universal)
-count univ and exist to decide negate or not
-find the rule of everything, where NotExist is treated as Univ
-Do not forget the unicorn. It has examples in the SICK ds
-In sample search, it is better to go back to log10. No
-What to do with relation predicates with one univ, one exist var. Ignore it.
-Contradicting MLNs return Z=1 but it should return Z=0
-How to do negation in text and hypothesis ? 
-When to negate H and when not ? (for computational efficieny). Looks like always negate
-Parsing bug in deallocation alchemy/src/parser/listobj.h. For now, deallocation disabled
-FIXED: Why IR changes affects p(-H) and p(H) differently ? (They do not).
-FIXED: Why p(H) not equal 1-p(-H) ?  Beucase of bug in parsing. Bug fixed
-FIXED: try examples 24,25,27,28 for more bugs in alchemy. Done
-FIXED: Infinite loop in HardAssumptionAsEvidenceProbabilisticTheoremProver in example 13. 
-FIXED: wierd handling of a formula like a(x)^b(y).
-FIXED: wrong handling of weights: infinity + w = 10 + w
-----------
SampleSearch:
-GM::reduceDomains can be better by removing functions that are always true
-what to do with LogFunction.h
-what to do with CPT.h
-what to do with SF.h
-------------------
-still, there are types problems in inference rules. I will disable recovering types for the current experiments
-paraphrase to logic
-prenex normal form 
-multiparses and svm
-get latest candc and boxer
-try to tune candc parameters to reduce no-parse 

-Can we use !H instead of H<->ent  to avoid the problem of H- ?
-H- now is bad bad bad.
-OR in PositiveEqEliminating could be wrong
-Negation in PositiveEqEliminating and HardAssumptionAsEvidence is absolutely wrong.

1-Naming of HardAssumptionAsEvidence and PositiveEqEliminating is not decriptive
5-fixDCA or noFixDCA is not implemented in PositiveEqEliminating (well, it automatically works if "-keepUniv false")

3-Existance is done for the outer most group of universals, not for embeded univs under exists
SUggestion: 
-STS is running RTE twice then average. Do not do both of them in one big MLN

how to parse multi-sentences T or H

//==========================================
Merging Cuong's fork with main(ToDo)
------------------------------
* Code of running condor is replaced with my scripts for condor. What is still missing is organizging the output and running the scripts on it. 
-Different sets of scripts are required for different data sets, STS, RTE, and Baroni

* Run the system on Torrento's dataset with their phrases.

* In AlchemyTheoremProver.scala, there is a function to generate rules based on wordnet, it is commented for now but it should not
//==========================================

-Function: InferenceRuleInjectingProbabilisticTheoremProver.convertParaphraseToFOL is completely wrong. 
espcially, How to map variables from LHS to RHS ? do we use a new Existential Quantifier ? 
Now, the mapping is so messed up. It is as it was implemented by coung
It is even worse. Now, it assumes that the phrases are a list of conjuncted predicates. This is wrong, we have rules contain negations. 

-How to generate rules for phrases. We need a principled way to extract phrases and map them to logical expressions.
Assuming we follow the technique we have now, there still a problem with it. e.g:
 A little boy is playing.	A fat girl is eating.
Phrases are: 
little boy	(correct)
fat girl	(correct)
little boy play	(not sure)
little play	(not sure)
boy play	(not sure)
fat girl eat	(not sure)
girl eat	(not sure)
fat eat		(not sure)
For now, all of them are possible phrases.

-Locking in Lucene will prevent parallalization in condor. 

-Tokenization:
Tokenization details and different modes of tokenization are in utcompling/mlnsemantics/datagen.Tokenize.scala

-Removing special characters: It is two steps, 
(a) removing quotes if the text is quoted before generating inference rules.  
(b) replace special characters with _ before convert to FOL in PredicateCleaningBoxerExpressionInterpreterDecorator
Is this the right place ? Should not it be right before calling MLN/PSL ? would it be better NOT to remove special characters. Instead, replace them with some other characters ?  I will keep it like this for now until I find an example where this needs to be changed. 
In all cases, candc gets somehow confused when parsing special characters. 
//==========================================Future enhancements
-When supporting embeded proposition, UnnecessarySubboxRemovingBoxerExpressionInterpreter has to change  (unremove theme and propositions)
-When parsing, WH questions are removed. This can be fixed here: BoxerExpressionParser
-Weighted universal rule to simulate generalized quantifiers.
//==========================================
830: takes 18 minutes: it is slightly changed to avoid this loong wait

597: type
610: type
679: type
803: type
1399: type


825: parsing (%) should be added to the forbidden char
904: parsing (#) should be added to the forbidden char
905: NotEqual: two variables unmatching types
1067: parsing (%) should be added to the forbidden char
1171: parsing (%) should be added to the forbidden char
1341: parsing (@) should be added to the forbidden char

1446: parsing (@) should be added to the forbidden char


remove predicates named topic_

remove _loc_, _nam_ ...


133: wrong parse
564: need a long paraphrasing rule
918: add a rule between two predicates if their characters are matching. E.g sew and sewing. 
940: we do not fix spelling mistakes. Maybe the hack above could help
152: kengaroo. Why do not we remove _POS_ ?? THink carefully about it. 
1321: people vs group of people
1024: wrong parse. pizza vs slice of pizza
245: wrong parse
852: wrong parse
951: wrong spelling of kangaroo. Slightly low weights. Solution on 918 may help a bit
DO WE ALLOW rules between non-matching POS predicates ???
963: terrible wrong parse for a very easy sentence. easy paraphrasing rule: chop up vs dice
1305: terrible wrong parse. No workaround can fix it.
95: wrong parse
1488: boxer's nasty way of doing AND
1040: wrong parse
9: crappy boxing. It needs clever code.
1131: paraprasing: apply butter = puttering, peice of bread vs bread
1449: missed correference resolution. how do handle "neuter" ?
223: wrong parse. 
7: verctor space weight is very very low. 
11: very low combination weights in case of very few lines

1072: try to replace all relations with REL instead of the name
r_of_dt(x, y) <=>  r_on_dt(y, x)
r_and_dh(x, y) => r_and_dh(y,x)

Try BP

Try removing all rel except agent, patient

terrible overestimated in PAR: 674, 531, 541, 712
=========================================================
PSL
2-Is it better to limit number of nulls ? 

3-replace "all" with "default". 

4-grounding of avg, entailment_h & entailment_t >> entailment  does not work correctly if one of the two predicates in the LHS is zero. It works as AND not AVG

5-Timeout: 498, 517, 664
Ill-posed optimization: 960, 1431
Zero because of error 4 above: 592, 924, 1418

============================================================
Logic: 
-Handling negation is wrong.  For now, it is replaced with dummy predicate
-Handling some of the equality contstraints is also wrong
